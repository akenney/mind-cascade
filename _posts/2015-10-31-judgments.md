---
layout: post
permalink: /judgments/
title: "Judgments"
date: 2015-10-31
published: true
---

People have to make judgments and decisions all the time.  Often, you do this based on intuition, without even thinking about it, and most of the time that has pretty reasonable results.  But sometimes our intuitions are wrong and we make judgments based on incorrect or irrelevant information.

Probability is an area where our intuition is notoriously bad in certain systematic ways.  Here are some examples:

* If you flip a coin five times, which is a more likely outcome, heads-heads-heads-heads-heads or heads-tails-heads-heads-tails?
* Suppose you have a werewolf detector that you can point at any person, and if the person is a werewolf then the detector will say so, and if the person isn't a werewolf then the detector will usually say they aren't but there's a 5% chance that the detector will be wrong and say they are.  If one out of every thousand people is a werewolf, and you pick a random person and your detector says they're a werewolf, how likely is it that they actually are?
* What's the smallest number of people you could put in a room to make it so that there's at least a 50% chance that two of them will have the same birthday?

Even if you know how to compute the correct answers, they're probably different from your intuition.

We're also not very good at certain types of logic.  For example, in the "Wason selection task", you are shown these cards (which have a number on one side and a color on the other):

<!-- from https://upload.wikimedia.org/wikipedia/commons/1/1e/Wason_selection_task_cards.svg -->
<img src="{{ site.baseurl }}/materials/5-judgments/wason-cards.svg" width="600px">

and you have to determine whether they all obey the rule "if the card has an even number on one side, it's red on the other side".  Which cards do you need to flip over?  The correct answer is the 8 and the brownish-orange card, but many people get this wrong.

We tend to think of something as more frequent if it's easier to think of examples of it (this is called the [availability heuristic](https://en.wikipedia.org/wiki/Availability_heuristic)).  In some such cases we might actually have inaccurate information - for example, if the media makes a big deal about ebola but doesn't mention the flu, people might reasonably worry more about getting ebola than about the flu.  In some cases, we have information but it's not easily accessible - for example, if you had to guess whether the letter L occurs more often as the first letter or third letter of a word, you're probably more likely to say first letter, which is wrong, but it's easier to think of words that have a particular first letter than a particular third letter.  In other cases, we have information that we know is biased but we use it anyway - for example, if someone is asked to talk about a topic they know a lot about, we'll think they're more knowledgeable in general, even though the topic was specifically selected to be one that the person knows about.

When trying to judge the quality or truth of something, people tend to look for evidence that would  confirm their belief or hypothesis, and not evidence against it (this is called [confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias)).  People are more likely to remember examples that support their opinions, and are more likely to judge methods supporting their opinions to be reasonable.

People tend to like things better that are more familiar.  You may have had experiences where you initially find a certain song or person or process annoying, but after being around it for a while, you come to like it.  Experiments have shown that if you've seen a picture before you'll probably like it better than one you haven't seen, and that if you write about a belief you have then you'll probably believe it more strongly.

The phrasing of a question or description can affect your judgments about it (this is called [framing](https://en.wikipedia.org/wiki/Framing_effect_%28psychology%29)).  For example, if people are registering for an event and are told they have to pay extra if they register late, they're a lot more likely to register early than if they're told they get a discount for registering early, even if the amount they'd pay for earlier registration is the same in each case.

Decisions are strongly affected by whatever initial baseline you have in your mind (this is called [anchoring](https://en.wikipedia.org/wiki/Anchoring#Anchoring_and_adjustment_heuristic)).  For example, suppose you want to buy a notebook, and you can either buy it at the store next door for $7 or go to a store a mile away and buy it for $2.  You'd probably at least consider going to the farther-away store in order to get the better deal.  But suppose you want to buy a new smartphone that costs $430 at the store next door or $425 at the store a mile away.  In that case, you probably don't really care about the difference in price - even though in both the notebook case and the smartphone case, you'd be saving the same $5 by going the same extra mile.

<!-- http://web.mit.edu/ariely/www/MIT/Papers/tom.pdf -->
Sometimes you don't have a good way of determining the baseline for making decisions, so you will follow things suggested by other people or the environment.  There's a famous example from the book *Tom Sawyer*, in which Tom gets his friends to pay him for the privilege of painting his fence, by acting like it's fun.  His friends don't have a baseline for deciding whether fence-painting is a boring chore or a fun activity, so when Tom acts like it's fun, they assume that it is.

<!-- http://nel.mit.edu/pdf/20CoherentArbcopy.pdf -->
Your decisions can sometimes be influenced by arbitrary baselines that are clearly unrelated to the decision, even when you would think you'd have a decent baseline already.  For example, if you're given a random number and you have to decide whether you'd pay that amount of money for some item, and then you have to decide how much you *would* pay for the item, you're willing to pay more if the random number was higher, even though you know the number was random.

Sometimes you think you're making a decision for a particular reason when the real reason is completely different (or there is no real reason).
<!-- http://l3d.cs.colorado.edu/~ctg/classes/cogsci12/rdg/nisbett-wilson.pdf -->
In one experiment, people had to judge which of several identical pairs of stockings was the best quality, and they were much more likely to pick whichever one was placed farthest to the right, but when asked why they picked it, none of them thought the position had mattered.
<!-- http://philpapers.org/archive/JOHFTD -->
In another experiment, people had to judge which of two faces was more attractive and then explain why, except sometimes the experimenter switched the pictures so that the person was actually explaining why they picked one when it wasn't the one they actually picked - and people usually didn't notice and gave explanations anyway.

Your judgments can sometimes be based on trying to perceive the world in a way that makes you feel better.  For example, when some people entered a lottery for some very hard-to-get sports tickets, the people who ended up getting the tickets then considered them to be much more valuable than people who didn't, even though they all started out wanting the tickets equally.  Similarly, if someone gets you to do a really boring task voluntarily, you will probably judge the task to be less boring than if you were doing it because you had to or because you got paid to - it's like your brain is saying, "I chose to do this thing, so it must not be *that* bad".  This effect is an example of [cognitive dissonance](https://en.wikipedia.org/wiki/Cognitive_dissonance).

<!-- http://pss.sagepub.com/content/10/1/80.abstract -->
In general, your judgments and behaviors are influenced by what you are expecting, and you can be made to expect different things.  For example, if you're thinking about a stereotype that applies to you, you're more likely to conform to that stereotype.  There was an experiment in which Asian girls were asked to write down either their gender or their ethnicity and then do a math task, and the ones who were asked to write down their gender did worse than a control group and the ones who were asked to write down their ethnicity did better, presumably because each group was thinking about the corresponding stereotypes: that "girls are bad at math" or that "Asians are good at math".  This is remarkable because it shows how people can perform differently well on a math test depending on factors unrelated to their actual math ability.

[Here](https://www.youtube.com/watch?v=gRnRIC9JQTQ) is a video you can watch about an experiment in which elementary school students' behavior is impacted by made-up stereotypes.

<!-- http://www.radford.edu/jaspelme/443/spring-2007/Articles/Snyder-Tanke-Bersheid-1977.pdf -->
A related experiment showed how people *act* more attractive when they are *perceived* by other people as attractive.  If you're expecting people to be a certain way, they can (consciously or subconsciously) pick up on that, and it can make them act that way even if they otherwise wouldn't have - so it's worthwhile to keep this in mind in situations where you might have preconceptions about people.

